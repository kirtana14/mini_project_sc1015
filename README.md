## Problem definition based on a dataset
Clearly defined the problem as predicting the likelihood of stroke using a range of health-related features.
Framed the objective in a real-world context — enabling early detection to support preventive healthcare.
Justified the importance of predicting stroke risk using available clinical data.

## Data preparation and cleaning
Handled missing values (e.g., ‘smoking_status’ column) using appropriate strategies.
Converted categorical variables (e.g., gender, work type) to numeric formats for modeling.
Ensured data consistency and proper formatting for model inputs.

## Exploratory data analysis/visualization 
Performed univariate and bivariate analysis to examine stroke distribution across features.
Used visualizations like histograms and bar plots to highlight patterns (e.g., age, heart disease, glucose levels).
Derived insights like:
Higher stroke rates among people with heart disease and hypertension.
Former smokers having unexpectedly high stroke rates.
Glucose levels and age being strong indicators.

## Use of machine learning techniques 
Applied and compared multiple models: Logistic Regression, Decision Trees, and more.
Evaluated models using metrics like accuracy, recall (TPR), FPR, and FNR.
Prioritized models that performed well on recall — due to the importance of detecting true stroke cases.
Learned new methods like feature importance interpretation and confusion matrix analysis.

## Data-driven insights and the recommendations
Generated clear, actionable insights based on EDA and model outputs.
Gave practical recommendations, such as:
Prioritizing screening for those with heart disease/hypertension.
Encouraging glucose control and long-term follow-up for former smokers.
Designing risk calculators that go beyond age thresholds.
Linked technical findings to real-world healthcare applications.


## Learning something new and doing something beyond this course
Explored medical context and connected technical results with health policies.
Compared multiple models and discussed trade-offs (e.g., recall vs. false positives).
Added thoughtful feature engineering and new perspectives in the recommendations.
